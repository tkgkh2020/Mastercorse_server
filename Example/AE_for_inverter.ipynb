{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE for inveret & save & load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算グラフ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'layer1/weight1:0' shape=(40, 20) dtype=float32_ref> <tf.Variable 'layer1/Variable:0' shape=(20,) dtype=float32_ref> Tensor(\"layer1/Relu1:0\", shape=(?, 20), dtype=float32)\n",
      "<tf.Variable 'layer2/weight2:0' shape=(20, 10) dtype=float32_ref> <tf.Variable 'layer2/Variable:0' shape=(10,) dtype=float32_ref> Tensor(\"layer2/Relu2:0\", shape=(?, 10), dtype=float32)\n",
      "<tf.Variable 'layer3/weight3:0' shape=(10, 20) dtype=float32_ref> <tf.Variable 'layer3/Variable:0' shape=(20,) dtype=float32_ref> Tensor(\"layer3/Relu3:0\", shape=(?, 20), dtype=float32)\n",
      "<tf.Variable 'layer4/weight4:0' shape=(20, 40) dtype=float32_ref> <tf.Variable 'layer4/Variable:0' shape=(40,) dtype=float32_ref> Tensor(\"layer4/add:0\", shape=(?, 40), dtype=float32)\n",
      "Tensor(\"loss/loss:0\", shape=(), dtype=float32)\n",
      "name: \"train/Adagrad\"\n",
      "op: \"NoOp\"\n",
      "input: \"^train/Adagrad/update_layer1/weight1/ApplyAdagrad\"\n",
      "input: \"^train/Adagrad/update_layer1/Variable/ApplyAdagrad\"\n",
      "input: \"^train/Adagrad/update_layer2/weight2/ApplyAdagrad\"\n",
      "input: \"^train/Adagrad/update_layer2/Variable/ApplyAdagrad\"\n",
      "input: \"^train/Adagrad/update_layer3/weight3/ApplyAdagrad\"\n",
      "input: \"^train/Adagrad/update_layer3/Variable/ApplyAdagrad\"\n",
      "input: \"^train/Adagrad/update_layer4/weight4/ApplyAdagrad\"\n",
      "input: \"^train/Adagrad/update_layer4/Variable/ApplyAdagrad\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf.set_random_seed(123)\n",
    "    tf_x = tf.placeholder(shape=[None, 40], dtype=tf.float32, name='tf_x')\n",
    "    tf_y = tf.placeholder(shape=[None, 40], dtype=tf.float32, name='tf_y')\n",
    "    \n",
    "    with tf.name_scope('layer1'):\n",
    "        weight1 = tf.Variable(tf.random_normal([40, 20], stddev=0.25), name='weight1')\n",
    "        bias1 = tf.Variable(tf.constant(0.0, shape=[20], name='bias1'))\n",
    "        h1 = tf.nn.relu(tf.matmul(tf_x, weight1) + bias1, name='Relu1')\n",
    "        print(weight1, bias1, h1)\n",
    "    \n",
    "    with tf.name_scope('layer2'):\n",
    "        weight2 = tf.Variable(tf.random_normal([20, 10], stddev=0.25), name='weight2')\n",
    "        bias2 = tf.Variable(tf.constant(0.0, shape=[10], name='bias2'))\n",
    "        h2 = tf.nn.relu(tf.matmul(h1, weight2) + bias2, name='Relu2')\n",
    "        print(weight2, bias2, h2)\n",
    "        \n",
    "    with tf.name_scope('layer3'):\n",
    "        weight3 = tf.Variable(tf.random_normal([10, 20], stddev=0.25), name='weight3')\n",
    "        bias3 = tf.Variable(tf.constant(0.0, shape=[20], name='bias3'))\n",
    "        h3 = tf.nn.relu(tf.matmul(h2, weight3) + bias3, name='Relu3')\n",
    "        print(weight3, bias3, h3)\n",
    "    \n",
    "    with tf.name_scope('layer4'):\n",
    "        weight4 = tf.Variable(tf.random_normal([20, 40], stddev=0.25), name='weight4')\n",
    "        bias4 = tf.Variable(tf.constant(0.0, shape=[40], name='bias4'))\n",
    "        out_put = tf.matmul(h3, weight4) + bias4\n",
    "        print(weight4, bias4, out_put)\n",
    "        \n",
    "    with tf.name_scope('loss'):\n",
    "        #loss = tf.reduce_sum(tf.square(tf_y - out_put), name='loss')\n",
    "        loss = tf.reduce_mean(tf.square(tf_y - out_put), name='loss')\n",
    "        print(loss)\n",
    "    \n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdagradOptimizer(0.05).minimize(loss)\n",
    "        print(train_step)\n",
    "    \n",
    "    # グラフを保存する．\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ生成(numpy vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# データを生成\n",
    "n=5000\n",
    "\n",
    "x_data = np.array([np.random.rand(40).astype(np.float32) for i in range(n)])\n",
    "y_data = x_data\n",
    "\n",
    "#トレーニングデータとテストデータに分割\n",
    "x_train, x_test = np.split(x_data,   [int(n/2)]) # 教師データ\n",
    "y_train, y_test = np.split(y_data, [int(n/2)]) # テスト用のデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行フェーズ&モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: 0.3280\n",
      "Epoch   50: 0.1149\n",
      "Epoch  100: 0.0882\n",
      "Epoch  150: 0.0857\n",
      "Epoch  200: 0.0847\n",
      "Epoch  250: 0.0840\n",
      "Epoch  300: 0.0835\n",
      "Epoch  350: 0.0832\n",
      "Epoch  400: 0.0829\n",
      "Epoch  450: 0.0826\n",
      "Epoch  500: 0.0824\n",
      "Epoch  550: 0.0822\n",
      "Epoch  600: 0.0820\n",
      "Epoch  650: 0.0818\n",
      "Epoch  700: 0.0817\n",
      "Epoch  750: 0.0815\n",
      "Epoch  800: 0.0814\n",
      "Epoch  850: 0.0812\n",
      "Epoch  900: 0.0811\n",
      "Epoch  950: 0.0810\n",
      "Epoch 1000: 0.0809\n",
      "Epoch 1050: 0.0808\n",
      "Epoch 1100: 0.0806\n",
      "Epoch 1150: 0.0805\n",
      "Epoch 1200: 0.0804\n",
      "Epoch 1250: 0.0803\n",
      "Epoch 1300: 0.0802\n",
      "Epoch 1350: 0.0801\n",
      "Epoch 1400: 0.0800\n",
      "Epoch 1450: 0.0799\n",
      "Epoch 1500: 0.0798\n",
      "Epoch 1550: 0.0797\n",
      "Epoch 1600: 0.0796\n",
      "Epoch 1650: 0.0795\n",
      "Epoch 1700: 0.0794\n",
      "Epoch 1750: 0.0793\n",
      "Epoch 1800: 0.0792\n",
      "Epoch 1850: 0.0792\n",
      "Epoch 1900: 0.0791\n",
      "Epoch 1950: 0.0790\n",
      "Epoch 2000: 0.0789\n",
      "Epoch 2050: 0.0789\n",
      "Epoch 2100: 0.0788\n",
      "Epoch 2150: 0.0787\n",
      "Epoch 2200: 0.0787\n",
      "Epoch 2250: 0.0786\n",
      "Epoch 2300: 0.0786\n",
      "Epoch 2350: 0.0785\n",
      "Epoch 2400: 0.0785\n",
      "Epoch 2450: 0.0784\n",
      "Epoch 2500: 0.0784\n",
      "Epoch 2550: 0.0783\n",
      "Epoch 2600: 0.0783\n",
      "Epoch 2650: 0.0782\n",
      "Epoch 2700: 0.0782\n",
      "Epoch 2750: 0.0782\n",
      "Epoch 2800: 0.0781\n",
      "Epoch 2850: 0.0781\n",
      "Epoch 2900: 0.0780\n",
      "Epoch 2950: 0.0780\n",
      "Epoch 3000: 0.0780\n",
      "Epoch 3050: 0.0779\n",
      "Epoch 3100: 0.0779\n",
      "Epoch 3150: 0.0779\n",
      "Epoch 3200: 0.0779\n",
      "Epoch 3250: 0.0778\n",
      "Epoch 3300: 0.0778\n",
      "Epoch 3350: 0.0778\n",
      "Epoch 3400: 0.0778\n",
      "Epoch 3450: 0.0777\n",
      "Epoch 3500: 0.0777\n",
      "Epoch 3550: 0.0777\n",
      "Epoch 3600: 0.0777\n",
      "Epoch 3650: 0.0777\n",
      "Epoch 3700: 0.0776\n",
      "Epoch 3750: 0.0776\n",
      "Epoch 3800: 0.0776\n",
      "Epoch 3850: 0.0776\n",
      "Epoch 3900: 0.0776\n",
      "Epoch 3950: 0.0775\n",
      "Epoch 4000: 0.0775\n",
      "Epoch 4050: 0.0775\n",
      "Epoch 4100: 0.0775\n",
      "Epoch 4150: 0.0775\n",
      "Epoch 4200: 0.0775\n",
      "Epoch 4250: 0.0775\n",
      "Epoch 4300: 0.0774\n",
      "Epoch 4350: 0.0774\n",
      "Epoch 4400: 0.0774\n",
      "Epoch 4450: 0.0774\n",
      "Epoch 4500: 0.0774\n",
      "Epoch 4550: 0.0774\n",
      "Epoch 4600: 0.0774\n",
      "Epoch 4650: 0.0774\n",
      "Epoch 4700: 0.0774\n",
      "Epoch 4750: 0.0773\n",
      "Epoch 4800: 0.0773\n",
      "Epoch 4850: 0.0773\n",
      "Epoch 4900: 0.0773\n",
      "Epoch 4950: 0.0773\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "\n",
    "\n",
    "#実行フェーズ\n",
    "n_epochs = 5000\n",
    "training_loss = []\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    \n",
    "    #変数を初期化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # TensorBoardで追跡する変数を定義\n",
    "    with tf.name_scope('summary'):\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        writer = tf.summary.FileWriter('logsdata/AE_graph', sess.graph)\n",
    "    \n",
    "    \n",
    "    #500エポックでモデルをトレーニング\n",
    "    for e in range(n_epochs):\n",
    "        c, _, summary = sess.run([loss, train_step, merged], feed_dict={tf_x: x_train, tf_y: y_train})\n",
    "        writer.add_summary(summary, e)\n",
    "        training_loss.append(c)\n",
    "        if not e % 50:\n",
    "            print('Epoch %4d: %.4f' % (e, c))\n",
    "    saver.save(sess, './savepoint/AE_graph/trained-model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行フェーズ&モデルの復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./savepoint/simple_AE_graph/trained-model\n",
      "40\n",
      "訓練誤差 0.077292\n",
      "テスト誤差 0.077451\n",
      "20\n",
      "2500\n",
      "[[ 0.93561393  0.05866493  0.         ...,  0.81629837  0.          4.36586332]\n",
      " [ 0.43313083  0.82458234  0.         ...,  1.21196818  0.          3.03750825]\n",
      " [ 1.19145846  0.09024311  0.         ...,  0.85157084  0.          3.57028413]\n",
      " ..., \n",
      " [ 0.8260926   0.49821252  0.         ...,  0.77290535  0.          3.23634052]\n",
      " [ 1.66103911  0.          0.         ...,  0.10277878  0.          3.76798463]\n",
      " [ 0.77298951  0.72629923  0.         ...,  0.34468395  0.          3.14709544]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    #計算グラフの復元\n",
    "    new_saver = tf.train.import_meta_graph('./savepoint/simple_AE_graph/trained-model.meta')\n",
    "    #実行フェーズでの値の復元\n",
    "    new_saver.restore(sess, './savepoint/simple_AE_graph/trained-model')\n",
    "    \n",
    "    w1 = sess.run('layer1/weight1:0', feed_dict={'tf_x:0' : x_test, 'tf_y:0' : y_test})\n",
    "    #print(w1)\n",
    "    print(len(w1))\n",
    "    \n",
    "    lo_train = sess.run('loss/loss:0', feed_dict={'tf_x:0' : x_train, 'tf_y:0' : y_train})\n",
    "    print(\"訓練誤差\",lo_train)\n",
    "    \n",
    "    lo_test = sess.run('loss/loss:0', feed_dict={'tf_x:0' : x_test, 'tf_y:0' : y_test})\n",
    "    print(\"テスト誤差\",lo_test)\n",
    "    \n",
    "    R1 = sess.run('layer1/Relu1:0', feed_dict={'tf_x:0' : x_train, 'tf_y:0' : y_train})\n",
    "    print(len(R1[0]))\n",
    "    print(len(R1))\n",
    "    print(R1)\n",
    "    \n",
    "    \"\"\"b = sess.run('bias:0', feed_dict={'tf_x:0' : x_test, 'tf_y:0' : y_test})\n",
    "    print(b)\n",
    "    \n",
    "    y_pred = sess.run('y_hat:0', feed_dict={'tf_x:0' : x_test})\n",
    "    print(y_pred)\n",
    "    print(len(y_pred[0]))\n",
    "    \n",
    "    c = sess.run('loss/cost:0', feed_dict={'tf_x:0' : x_test, 'tf_y:0' : y_test})\n",
    "    print(c)\n",
    "    \n",
    "    t_op = sess.run('train/train_op', feed_dict={'tf_x:0' : x_test, 'tf_y:0' : y_test})\n",
    "    print(t_op)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
