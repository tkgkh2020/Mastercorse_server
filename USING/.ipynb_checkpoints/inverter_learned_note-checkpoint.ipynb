{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習済みのinverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ読み込みのための関数(バッチ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as ra\n",
    "import os\n",
    "import glob\n",
    "from numpy.random import *\n",
    "import time\n",
    "\n",
    "def batch(batch_size):\n",
    "    #batch_size = 60\n",
    "\n",
    "    #再構成した画像のPATHのリスト\n",
    "    path_rec = \"/opt/pfw/dragon_ball_reconsted/reconsted/disc11/story3/*.npy\"\n",
    "    filelists_rec = glob.glob(path_rec, recursive=True)\n",
    "\n",
    "    #zのPATHのリスト\n",
    "    path_z = \"/opt/pfw/dragon_ball_reconsted/z/disc11/story3/*.npy\"\n",
    "    filelists_z = glob.glob(path_z, recursive=True)\n",
    "\n",
    "    #サンプルしてくるインデックスのリスト\n",
    "    ind = ra.sample(range(len(filelists_rec)), batch_size)\n",
    "\n",
    "    #サンプルしてくるインデックスの各PATHを格納したリスト\n",
    "    batch_images_rec = [filelists_rec[i] for i in ind ]\n",
    "    batch_images_z = [filelists_z[i] for i in ind ]\n",
    "\n",
    "    #再構成した画像とzの各バッチ\n",
    "    batch_x = np.array([np.load(f).tolist() for f in batch_images_rec]) #再構成画像のファイル読み込み\n",
    "    batch_z = np.array([np.load(f).tolist() for f in batch_images_z]) #zのファイル読み込み\n",
    "    \n",
    "    return batch_x, batch_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./savepoint/inverter_graph/train_epoch_60000/trained-model\n",
      "121.88\n",
      "None\n",
      "(1, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00953451,  0.0307411 ,  0.04841327, -0.08912477, -0.00367212,\n",
       "         0.01107763,  0.02331166,  0.19427101,  0.01636336,  0.03547521,\n",
       "         0.27695984,  0.00467675,  0.01041173,  0.02888585, -0.04662186,\n",
       "         0.02019877, -0.20774083,  0.23417857, -0.04925729,  0.02213304,\n",
       "         0.0191018 , -0.06105234,  0.01366773,  0.02749317, -0.05714776,\n",
       "         0.01737077,  0.12659313,  0.0084565 ,  0.02046099, -0.03062566,\n",
       "         0.21234687, -0.00666096, -0.00066855,  0.0187257 ,  0.1757189 ,\n",
       "         0.02381668, -0.20937061,  0.02915876,  0.02929257,  0.03760717,\n",
       "        -0.00633414,  0.01858837, -0.01943819,  0.01024514, -0.00047842,\n",
       "        -0.07171699, -0.02979955, -0.00224349,  0.04704698,  0.09441631,\n",
       "         0.02106768, -0.0331798 ,  0.15268654,  0.02800318,  0.03271685,\n",
       "        -0.06585322,  0.01947626,  0.03168476,  0.01800863,  0.00937171,\n",
       "         0.02423463,  0.02875223,  0.00256147,  0.02498393,  0.01952708,\n",
       "         0.00688007,  0.01408795,  0.00200796,  0.00119229,  0.00693518,\n",
       "         0.15682457, -0.24062566,  0.0035933 ,  0.02313104,  0.0161604 ,\n",
       "         0.02557761,  0.02390527,  0.21553619,  0.04732765,  0.10561921,\n",
       "         0.01701932,  0.01815372, -0.00183323,  0.01041078,  0.01822927,\n",
       "        -0.14320901,  0.02478166,  0.00303862, -0.01940625,  0.0149472 ,\n",
       "         0.03557031,  0.02389762,  0.0666685 ,  0.0264933 ,  0.04277011,\n",
       "         0.00127184, -0.08697581, -0.04643379, -0.0546347 ,  0.00792979]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as ra\n",
    "import os\n",
    "import glob\n",
    "from numpy.random import *\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "n_epochs = 50000000\n",
    "training_loss = []\n",
    "eps = 0.01\n",
    "batch_size = 1\n",
    "batch_x, batch_z = batch(batch_size)\n",
    "kp_p = 1.0\n",
    "\n",
    "epo = 60000\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    #計算グラフの復元\n",
    "    new_saver = tf.train.import_meta_graph('./savepoint/inverter_graph/train_epoch_'+str(epo)+'/trained-model.meta')\n",
    "    #実行フェーズでの値の復元\n",
    "    new_saver.restore(sess, './savepoint/inverter_graph/train_epoch_'+str(epo)+'/trained-model')\n",
    "    \n",
    "    loss = sess.run('loss/loss:0', feed_dict={'Placeholder:0' : batch_x, 'Placeholder_1:0' : batch_z, 'Placeholder_2:0' : kp_p})\n",
    "    train_step = sess.run('train/Adam', feed_dict={'Placeholder:0' : batch_x, 'Placeholder_1:0' : batch_z, 'Placeholder_2:0' : kp_p})\n",
    "    y = sess.run('fully4/add:0', feed_dict={'Placeholder:0' : batch_x, 'Placeholder_1:0' : batch_z, 'Placeholder_2:0' : kp_p})\n",
    "    print(loss)\n",
    "    print(train_step)\n",
    "    print(y.shape)\n",
    "    #print(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータの生成(選定した動画を使う)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as ra\n",
    "import os\n",
    "import glob\n",
    "from numpy.random import *\n",
    "import time\n",
    "\n",
    "batch_size = 60\n",
    "\n",
    "def batch(batch_size):\n",
    "    #batch_size = 60\n",
    "\n",
    "    #再構成した画像のPATHのリスト\n",
    "    path_rec = \"/opt/pfw/dragon_ball_reconsted/reconsted/disc11/story3/*.npy\"\n",
    "    filelists_rec = glob.glob(path_rec, recursive=True)\n",
    "    print(len(filelists_rec))\n",
    "\n",
    "    #zのPATHのリスト\n",
    "    path_z = \"/opt/pfw/dragon_ball_reconsted/z/disc11/story3/*.npy\"\n",
    "    filelists_z = glob.glob(path_z, recursive=True)\n",
    "    print(len(filelists_z))\n",
    "\n",
    "    #サンプルしてくるインデックスのリスト(クリリンのデータのindex)\n",
    "    ind = []\n",
    "    i = 898\n",
    "    while(1):\n",
    "        ind.append(i)\n",
    "        i = i+1\n",
    "        if(i > 1200):\n",
    "            break\n",
    "    print(ind)\n",
    "    \n",
    "    #サンプルしてくるインデックスの各PATHを格納したリスト\n",
    "    batch_images_rec = [filelists_rec[i] for i in ind ]\n",
    "    batch_images_z = [filelists_z[i] for i in ind ]\n",
    "\n",
    "    #再構成した画像とzの各バッチ\n",
    "    batch_x = np.array([np.load(f).tolist() for f in batch_images_rec]) #再構成画像のファイル読み込み\n",
    "    batch_z = np.array([np.load(f).tolist() for f in batch_images_z]) #zのファイル読み込み\n",
    "    \n",
    "    return batch_x, batch_z\n",
    "\n",
    "#batch_x, batch_z = batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42854\n",
      "42854\n",
      "[898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200]\n",
      "INFO:tensorflow:Restoring parameters from ./savepoint/inverter_graph/train_epoch_60000/trained-model\n",
      "40474.7\n",
      "None\n",
      "(303, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00953583,  0.03073959,  0.04841126, ..., -0.04643112,\n",
       "        -0.05462735,  0.00792682],\n",
       "       [ 0.00953583,  0.03073959,  0.04841126, ..., -0.04643112,\n",
       "        -0.05462735,  0.00792682],\n",
       "       [ 0.00953583,  0.03073959,  0.04841126, ..., -0.04643112,\n",
       "        -0.05462735,  0.00792682],\n",
       "       ..., \n",
       "       [ 0.00953583,  0.03073959,  0.04841126, ..., -0.04643112,\n",
       "        -0.05462735,  0.00792682],\n",
       "       [ 0.00953583,  0.03073959,  0.04841126, ..., -0.04643112,\n",
       "        -0.05462735,  0.00792682],\n",
       "       [ 0.00953583,  0.03073959,  0.04841126, ..., -0.04643112,\n",
       "        -0.05462735,  0.00792682]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as ra\n",
    "import os\n",
    "import glob\n",
    "from numpy.random import *\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "n_epochs = 50000000\n",
    "training_loss = []\n",
    "eps = 0.01\n",
    "batch_size = 1\n",
    "batch_x, batch_z = batch(batch_size)\n",
    "kp_p = 1.0\n",
    "\n",
    "epo = 60000\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    #計算グラフの復元\n",
    "    new_saver = tf.train.import_meta_graph('./savepoint/inverter_graph/train_epoch_'+str(epo)+'/trained-model.meta')\n",
    "    #実行フェーズでの値の復元\n",
    "    new_saver.restore(sess, './savepoint/inverter_graph/train_epoch_'+str(epo)+'/trained-model')\n",
    "    \n",
    "    loss = sess.run('loss/loss:0', feed_dict={'Placeholder:0' : batch_x, 'Placeholder_1:0' : batch_z, 'Placeholder_2:0' : kp_p})\n",
    "    train_step = sess.run('train/Adam', feed_dict={'Placeholder:0' : batch_x, 'Placeholder_1:0' : batch_z, 'Placeholder_2:0' : kp_p})\n",
    "    y = sess.run('fully4/add:0', feed_dict={'Placeholder:0' : batch_x, 'Placeholder_1:0' : batch_z, 'Placeholder_2:0' : kp_p})\n",
    "    print(loss)\n",
    "    print(train_step)\n",
    "    print(y.shape)\n",
    "    #print(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00953583,  0.03073959,  0.04841126, -0.08912443, -0.00366896,\n",
       "        0.01107523,  0.02330996,  0.19427341,  0.01636409,  0.0354729 ,\n",
       "        0.27695122,  0.00467552,  0.0104119 ,  0.02888443, -0.04659704,\n",
       "        0.02019764, -0.2077367 ,  0.23417743, -0.04926359,  0.02213626,\n",
       "        0.01910026, -0.0610526 ,  0.01366673,  0.02749078, -0.05714435,\n",
       "        0.01737012,  0.12659231,  0.00845952,  0.02046065, -0.03062916,\n",
       "        0.21233311, -0.00666334, -0.0006662 ,  0.01873057,  0.17571205,\n",
       "        0.02381505, -0.2093676 ,  0.02915475,  0.02929306,  0.03760639,\n",
       "       -0.00633434,  0.01859134, -0.01943806,  0.01024536, -0.00046861,\n",
       "       -0.07169482, -0.02980214, -0.00224469,  0.04704423,  0.0944192 ,\n",
       "        0.02106553, -0.03317888,  0.15267985,  0.02800331,  0.03272066,\n",
       "       -0.06585484,  0.01947527,  0.03168437,  0.01800701,  0.00937015,\n",
       "        0.02423237,  0.02875237,  0.00256073,  0.024985  ,  0.01952176,\n",
       "        0.00687983,  0.01408372,  0.00201059,  0.00118781,  0.00693381,\n",
       "        0.15681796, -0.2406078 ,  0.00359488,  0.02313129,  0.0161581 ,\n",
       "        0.02557819,  0.023905  ,  0.21552655,  0.04733174,  0.10560672,\n",
       "        0.01701496,  0.01815338, -0.00183133,  0.01040957,  0.01822689,\n",
       "       -0.1431855 ,  0.02478284,  0.00304093, -0.01940512,  0.01494953,\n",
       "        0.03556859,  0.02389985,  0.06665781,  0.02649422,  0.042769  ,\n",
       "        0.00125833, -0.08697303, -0.04643112, -0.05462735,  0.00792682], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(y[0]))\n",
    "print(len(y))\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDSの入力データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ind = []\n",
    "i = 898\n",
    "while(1):\n",
    "    ind.append(i)\n",
    "    i = i+1\n",
    "    if(i > 1200):\n",
    "        break\n",
    "print(len(ind))\n",
    "\n",
    "for j in range(len(ind)):\n",
    "    np.save('/mnt/nfs/takagi/Mastercorse_program/Picture_future_world/inverter_LDS/USING/LDS_input/di11_sry3_sce4_Cririn/img_'+str(ind[j])+'_z.npy', y[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "(100, 1)\n",
      "[[ 0.00953583]\n",
      " [ 0.03073959]\n",
      " [ 0.04841126]\n",
      " [-0.08912443]\n",
      " [-0.00366896]\n",
      " [ 0.01107523]\n",
      " [ 0.02330996]\n",
      " [ 0.19427341]\n",
      " [ 0.01636409]\n",
      " [ 0.0354729 ]\n",
      " [ 0.27695122]\n",
      " [ 0.00467552]\n",
      " [ 0.0104119 ]\n",
      " [ 0.02888443]\n",
      " [-0.04659704]\n",
      " [ 0.02019764]\n",
      " [-0.2077367 ]\n",
      " [ 0.23417743]\n",
      " [-0.04926359]\n",
      " [ 0.02213626]\n",
      " [ 0.01910026]\n",
      " [-0.0610526 ]\n",
      " [ 0.01366673]\n",
      " [ 0.02749078]\n",
      " [-0.05714435]\n",
      " [ 0.01737012]\n",
      " [ 0.12659231]\n",
      " [ 0.00845952]\n",
      " [ 0.02046065]\n",
      " [-0.03062916]\n",
      " [ 0.21233311]\n",
      " [-0.00666334]\n",
      " [-0.0006662 ]\n",
      " [ 0.01873057]\n",
      " [ 0.17571205]\n",
      " [ 0.02381505]\n",
      " [-0.2093676 ]\n",
      " [ 0.02915475]\n",
      " [ 0.02929306]\n",
      " [ 0.03760639]\n",
      " [-0.00633434]\n",
      " [ 0.01859134]\n",
      " [-0.01943806]\n",
      " [ 0.01024536]\n",
      " [-0.00046861]\n",
      " [-0.07169482]\n",
      " [-0.02980214]\n",
      " [-0.00224469]\n",
      " [ 0.04704423]\n",
      " [ 0.0944192 ]\n",
      " [ 0.02106553]\n",
      " [-0.03317888]\n",
      " [ 0.15267985]\n",
      " [ 0.02800331]\n",
      " [ 0.03272066]\n",
      " [-0.06585484]\n",
      " [ 0.01947527]\n",
      " [ 0.03168437]\n",
      " [ 0.01800701]\n",
      " [ 0.00937015]\n",
      " [ 0.02423237]\n",
      " [ 0.02875237]\n",
      " [ 0.00256073]\n",
      " [ 0.024985  ]\n",
      " [ 0.01952176]\n",
      " [ 0.00687983]\n",
      " [ 0.01408372]\n",
      " [ 0.00201059]\n",
      " [ 0.00118781]\n",
      " [ 0.00693381]\n",
      " [ 0.15681796]\n",
      " [-0.2406078 ]\n",
      " [ 0.00359488]\n",
      " [ 0.02313129]\n",
      " [ 0.0161581 ]\n",
      " [ 0.02557819]\n",
      " [ 0.023905  ]\n",
      " [ 0.21552655]\n",
      " [ 0.04733174]\n",
      " [ 0.10560672]\n",
      " [ 0.01701496]\n",
      " [ 0.01815338]\n",
      " [-0.00183133]\n",
      " [ 0.01040957]\n",
      " [ 0.01822689]\n",
      " [-0.1431855 ]\n",
      " [ 0.02478284]\n",
      " [ 0.00304093]\n",
      " [-0.01940512]\n",
      " [ 0.01494953]\n",
      " [ 0.03556859]\n",
      " [ 0.02389985]\n",
      " [ 0.06665781]\n",
      " [ 0.02649422]\n",
      " [ 0.042769  ]\n",
      " [ 0.00125833]\n",
      " [-0.08697303]\n",
      " [-0.04643112]\n",
      " [-0.05462735]\n",
      " [ 0.00792682]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ind = []\n",
    "i = 898\n",
    "while(1):\n",
    "    ind.append(i)\n",
    "    i = i+1\n",
    "    if(i > 1200):\n",
    "        break\n",
    "Y=[]\n",
    "for j in range(len(ind)):\n",
    "    img_z = np.load('/mnt/nfs/takagi/Mastercorse_program/Picture_future_world/inverter_LDS/USING/LDS_input/di11_sry3_sce4_Cririn/img_'+str(ind[j])+'_z.npy')\n",
    "    img_z_mat = np.mat(img_z)\n",
    "    Y.append(img_z_mat.T)\n",
    "\n",
    "print(Y[0].dtype)\n",
    "print(Y[0].shape)\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "(100, 1)\n",
      "[[-0.8555483 ]\n",
      " [ 0.45969465]\n",
      " [ 0.09905538]\n",
      " [ 0.72545197]\n",
      " [ 1.61104584]\n",
      " [-0.59295008]\n",
      " [-3.50500016]\n",
      " [ 2.89317583]\n",
      " [ 2.25022023]\n",
      " [-0.08809212]\n",
      " [ 1.23746634]\n",
      " [-0.62429133]\n",
      " [-1.33571881]\n",
      " [-0.82418635]\n",
      " [ 0.67269396]\n",
      " [-0.20740279]\n",
      " [-0.1928766 ]\n",
      " [-0.25434984]\n",
      " [ 2.20930866]\n",
      " [ 0.87045643]\n",
      " [ 2.15433896]\n",
      " [ 0.79687008]\n",
      " [-0.13308129]\n",
      " [-1.24337916]\n",
      " [-0.075297  ]\n",
      " [-1.45252638]\n",
      " [ 0.35192191]\n",
      " [-0.06977557]\n",
      " [-0.35428504]\n",
      " [ 3.26807273]\n",
      " [-0.10477834]\n",
      " [-0.80414649]\n",
      " [ 1.53388864]\n",
      " [-2.19610299]\n",
      " [ 1.77148439]\n",
      " [-1.85178169]\n",
      " [ 0.84446787]\n",
      " [-0.7278737 ]\n",
      " [-0.42498893]\n",
      " [ 0.12115465]\n",
      " [-0.81159654]\n",
      " [ 1.08201464]\n",
      " [-0.18100702]\n",
      " [-1.52301848]\n",
      " [-1.50389751]\n",
      " [ 1.22595861]\n",
      " [ 1.00323846]\n",
      " [-3.42658373]\n",
      " [ 0.95648194]\n",
      " [-0.59520279]\n",
      " [-1.43630923]\n",
      " [-0.94643937]\n",
      " [ 0.29768131]\n",
      " [-0.26405972]\n",
      " [ 1.22076588]\n",
      " [ 0.07271225]\n",
      " [ 0.3171292 ]\n",
      " [ 0.92515723]\n",
      " [ 0.34736995]\n",
      " [-0.5440912 ]\n",
      " [-2.26147955]\n",
      " [-1.13522553]\n",
      " [-2.55793086]\n",
      " [-1.04894332]\n",
      " [-2.28351527]\n",
      " [-0.37467153]\n",
      " [-0.35776389]\n",
      " [-3.13682756]\n",
      " [-1.64083505]\n",
      " [-0.4937773 ]\n",
      " [-1.57911313]\n",
      " [-2.06976928]\n",
      " [ 2.04207298]\n",
      " [ 0.78082469]\n",
      " [ 1.09681058]\n",
      " [-0.881673  ]\n",
      " [ 1.74434674]\n",
      " [-1.38369968]\n",
      " [ 1.33105712]\n",
      " [ 0.954973  ]\n",
      " [ 1.53216324]\n",
      " [-0.24631745]\n",
      " [-1.19058699]\n",
      " [-1.08921355]\n",
      " [-2.4862377 ]\n",
      " [-1.08289902]\n",
      " [ 0.70776161]\n",
      " [-1.17064276]\n",
      " [ 0.16546049]\n",
      " [ 0.14351902]\n",
      " [-1.62386329]\n",
      " [-0.16403865]\n",
      " [ 0.11318712]\n",
      " [ 0.38085953]\n",
      " [ 0.13266642]\n",
      " [ 0.93840554]\n",
      " [-1.48567418]\n",
      " [ 1.59443424]\n",
      " [-0.63791246]\n",
      " [-2.63445787]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dms = 100\n",
    "dmo = 100\n",
    "dt = 0.1\n",
    "x =np.mat(np.zeros([dms, 1]))\n",
    "A = np.mat(np.eye(dms, dms))\n",
    "C = np.mat(np.eye(dmo, dms))\n",
    "Q = np.mat(np.eye(dms, dms))\n",
    "R = np.mat(np.eye(dmo, dmo))\n",
    "    \n",
    "#print(\"A\\n%s\\nC\\n%s\\nQ\\n%s\\nR\\n%s\" % (A, C, Q, R))\n",
    "    \n",
    "X = [] # 状態\n",
    "Y = [] # 観測\n",
    "K = 500 # サンプル数\n",
    "for i in range(K):\n",
    "    x = A * x + np.mat(np.random.multivariate_normal(np.zeros(dms).tolist(),Q)).T\n",
    "    y = C * x + np.mat(np.random.multivariate_normal(np.zeros(dmo).tolist(),R)).T\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "\n",
    "print(Y[0].dtype)\n",
    "print(Y[0].shape)\n",
    "print(Y[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
