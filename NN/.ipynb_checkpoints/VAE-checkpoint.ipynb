{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Add, Multiply\n",
    "from keras.models import Model, Sequential\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "original_dim = 784\n",
    "intermediate_dim = 256\n",
    "latent_dim = 2\n",
    "batch_size = 100\n",
    "epochs = 50\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    \"\"\" Negative log likelihood (Bernoulli). \"\"\"\n",
    "\n",
    "    # keras.losses.binary_crossentropy gives the mean\n",
    "    # over the last axis. we require the sum\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDivergenceLayer(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch = - .5 * K.sum(1 + log_var -\n",
    "                                K.square(mu) -\n",
    "                                K.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Sequential([\n",
    "    Dense(intermediate_dim, input_dim=latent_dim, activation='relu'),\n",
    "    Dense(original_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "x = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "\n",
    "z_mu = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "z_mu, z_log_var = KLDivergenceLayer()([z_mu, z_log_var])\n",
    "z_sigma = Lambda(lambda t: K.exp(.5*t))(z_log_var)\n",
    "\n",
    "eps = Input(tensor=K.random_normal(stddev=epsilon_std,\n",
    "                                   shape=(K.shape(x)[0], latent_dim)))\n",
    "z_eps = Multiply()([z_sigma, eps])\n",
    "z = Add()([z_mu, z_eps])\n",
    "\n",
    "x_pred = decoder(z)\n",
    "\n",
    "vae = Model(inputs=[x, eps], outputs=x_pred)\n",
    "vae.compile(optimizer='rmsprop', loss=nll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the VAE on MNIST digits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, original_dim) / 255.\n",
    "x_test = x_test.reshape(-1, original_dim) / 255.\n",
    "\n",
    "vae.fit(x_train,\n",
    "        x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "\n",
    "# linearly spaced coordinates on the unit square were transformed\n",
    "# through the inverse CDF (ppf) of the Gaussian to produce values\n",
    "# of the latent variables z, since the prior of the latent space\n",
    "# is Gaussian\n",
    "u_grid = np.dstack(np.meshgrid(np.linspace(0.05, 0.95, n),\n",
    "                               np.linspace(0.05, 0.95, n)))\n",
    "z_grid = norm.ppf(u_grid)\n",
    "x_decoded = decoder.predict(z_grid.reshape(n*n, 2))\n",
    "x_decoded = x_decoded.reshape(n, n, digit_size, digit_size)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(np.block(list(map(list, x_decoded))), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
